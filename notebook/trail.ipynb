{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from glob import glob \n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from src.config import *\n",
    "from src.dataset import DataModule\n",
    "from src.model import LightningNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # base_model_name = 'efficientnet_b0'\n",
    "    # model = LightningNetwork(\n",
    "    #         base_model=get_base_model(base_model_name),\n",
    "    #         dropout=0.2, \n",
    "    #         output_dims=[128, 64],\n",
    "    #         learning_rate=LEARNING_RATE\n",
    "    # )\n",
    "    # data_module = DataModule(model_name=base_model_name)\n",
    "\n",
    "    # trainer = pl.Trainer(\n",
    "    #     logger=True,\n",
    "    #     # accelerator=ACCELERATOR,\n",
    "    #     # devices=DEVICES,\n",
    "    #     max_epochs=NUM_EPOCHS,\n",
    "    #     # precision=PRECISION,\n",
    "    #     # max_steps=5,\n",
    "    #     # fast_dev_run=True\n",
    "    #     # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    # )\n",
    "    # trainer.fit(model, data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32, 512, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Optional\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, base_model, dropout: float, output_dims: List[int]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = base_model\n",
    "        input_dim: int = base_model.classifier[1].in_features\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        for output_dim in output_dims:\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = output_dim\n",
    "        layers.append(nn.Linear(input_dim, NUM_CLASSES))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.base_model.classifier = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "class LightningNetwork(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 base_model,\n",
    "                 dropout: float, \n",
    "                 output_dims: List[int],\n",
    "                 learning_rate: float) -> None:\n",
    "    \n",
    "        super().__init__()\n",
    "        self.model = Network(base_model=base_model, dropout=dropout, output_dims=output_dims)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self.recall = torchmetrics.Recall(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self.auc = torchmetrics.AUROC(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "\n",
    "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(data)\n",
    "\n",
    "    def _common_step(self, batch: List[torch.Tensor], batch_idx: int) -> List[torch.Tensor]:\n",
    "        feature, target = batch\n",
    "        output = self.forward(feature)\n",
    "        loss = self.loss_fn(output, target)\n",
    "        return loss, output, target\n",
    "\n",
    "    def training_step(self, batch: List[torch.Tensor], batch_idx: int) -> dict:\n",
    "        loss, output, target = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "            },\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        # return {\"loss\": loss, \"output\": output, \"target\": target}\n",
    "\n",
    "    # TODO: THE CORRECT VERSION\n",
    "    def validation_step(self, batch: List[torch.Tensor], batch_idx: int) -> dict:\n",
    "        loss, output, target = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_loss\": loss,\n",
    "                \"val_acc\": self.accuracy(output, target),\n",
    "                \"val_f1\": self.f1_score(output, target),\n",
    "                \"val_recall\": self.recall(output, target),\n",
    "                \"val_precision\": self.precision(output, target),\n",
    "                # \"val_auc\": self.auc(outputs, targets),\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        return {\"loss\": loss, \"output\": output, \"target\": target}\n",
    "\n",
    "    # def validation_step(self, batch: List[torch.Tensor], batch_idx: int) -> dict:\n",
    "    #     loss, output, target = self._common_step(batch, batch_idx)\n",
    "    #     import random\n",
    "    #     y_pred = torch.Tensor([random.randint(0, 2) for _ in range(50)])\n",
    "    #     y_true = torch.Tensor([random.randint(0, 2) for _ in range(50)])\n",
    "    #     # self.validation_step_outputs.append(\n",
    "    #     #     {\n",
    "    #     #         \"loss\": loss, \n",
    "    #     #         \"output\": output, \n",
    "    #     #         \"target\": target\n",
    "    #     #     }   \n",
    "    #     # )\n",
    "\n",
    "    #     self.log_dict(\n",
    "    #         {\n",
    "    #             \"val_loss\": loss,\n",
    "    #             \"val_acc\": self.accuracy(y_pred, y_true),\n",
    "    #             \"val_f1\": self.f1_score(y_pred, y_true),\n",
    "    #             \"val_recall\": self.recall(y_pred, y_true),\n",
    "    #             \"val_precision\": self.precision(y_pred, y_true),\n",
    "    #             # \"val_auc\": self.auc(outputs, targets),\n",
    "    #         },\n",
    "    #         on_step=False,\n",
    "    #         on_epoch=True,\n",
    "    #         prog_bar=True,\n",
    "    #     )\n",
    "\n",
    "    \n",
    "    def test_step(self, batch: List[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        loss, output, target = self._common_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch: List[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        feature, _ = batch\n",
    "        feature = feature.reshape(feature.size(0), -1)\n",
    "        output = self.forward(feature)\n",
    "        # TODO: check if categorical or sparse labels are needed\n",
    "        preds = torch.argmax(output, dim=-1)\n",
    "        return preds\n",
    "    \n",
    "    # # def on_train_epoch_end(self, outputs: torch.Tensor) -> None:\n",
    "    # def on_train_epoch_end(self, outputs: List[dict]) -> None:\n",
    "    #     outputs = torch.cat([x[\"output\"] for x in outputs])\n",
    "    #     targets = torch.cat([x[\"target\"] for x in outputs])\n",
    "    #     self.log_dict(\n",
    "    #         {\n",
    "    #             \"train_acc\": self.accuracy(outputs, targets),\n",
    "    #             \"train_f1\": self.f1_score(outputs, targets),\n",
    "    #             \"train_recall\": self.recall(outputs, targets),\n",
    "    #             \"train_precision\": self.precision(outputs, targets),\n",
    "    #             \"train_auc\": self.auc(outputs, targets),\n",
    "    #         },\n",
    "    #         on_step=False,\n",
    "    #         on_epoch=True,\n",
    "    #         prog_bar=True,\n",
    "    #     )\n",
    "\n",
    "    # def on_validation_epoch_end(self) -> None:\n",
    "    # # def on_validation_epoch_end(self, outputs: torch.Tensor) -> None:\n",
    "    #     outputs = torch.stack([x['output'] for x in self.validation_step_outputs])\n",
    "    #     targets = torch.stack([x['target'] for x in self.validation_step_outputs])\n",
    "    #     losses = torch.stack([x['loss'] for x in self.validation_step_outputs])\n",
    "\n",
    "    #     self.log_dict(\n",
    "    #         {\n",
    "    #             \"val_loss\": losses.mean(),\n",
    "    #             \"val_acc\": self.accuracy(outputs, targets),\n",
    "    #             \"val_f1\": self.f1_score(outputs, targets),\n",
    "    #             \"val_recall\": self.recall(outputs, targets),\n",
    "    #             \"val_precision\": self.precision(outputs, targets),\n",
    "    #             # \"val_auc\": self.auc(outputs, targets),\n",
    "    #         },\n",
    "    #         on_step=False,\n",
    "    #         on_epoch=True,\n",
    "    #         prog_bar=True,\n",
    "    #     )\n",
    "    \n",
    "    def configure_optimizers(self) -> optim.Optimizer:\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4200)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import random\n",
    "# y_pred = torch.Tensor([random.randint(0, 2) for _ in range(50)])\n",
    "# y_true = torch.Tensor([random.randint(0, 2) for _ in range(50)])\n",
    "# accuracy = torchmetrics.Recall(task=\"multiclass\", num_classes=3)\n",
    "\n",
    "# acc = accuracy(y_pred, y_true)\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | model     | Network             | 4.2 M \n",
      "1 | loss_fn   | CrossEntropyLoss    | 0     \n",
      "2 | accuracy  | MulticlassAccuracy  | 0     \n",
      "3 | recall    | MulticlassRecall    | 0     \n",
      "4 | precision | MulticlassPrecision | 0     \n",
      "5 | f1_score  | MulticlassF1Score   | 0     \n",
      "6 | auc       | MulticlassAUROC     | 0     \n",
      "--------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 M     Total params\n",
      "16.720    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7fa115bc3d4fb79c880b0957063441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55cc6fcb51b404b8936be0ebe60eb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ca93b1f9ed479e962a053229de989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc                    0.0\n",
      "         val_f1                     0.0\n",
      "        val_loss             1.089205026626587\n",
      "      val_precision                 0.0\n",
      "       val_recall                   0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.089205026626587,\n",
       "  'val_acc': 0.0,\n",
       "  'val_f1': 0.0,\n",
       "  'val_recall': 0.0,\n",
       "  'val_precision': 0.0}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_name = 'efficientnet_b0'\n",
    "model = LightningNetwork(\n",
    "        base_model=get_base_model(base_model_name),\n",
    "        dropout=0.2, \n",
    "        output_dims=[128, 64],\n",
    "        learning_rate=0.002\n",
    ")\n",
    "data_module = DataModule(model_name=base_model_name)\n",
    "\n",
    "# logger = TensorBoardLogger(\n",
    "#     save_dir=\"../logs/tb_logs\", \n",
    "#     name=\"trail_v1\"\n",
    "# )\n",
    "# profiler = PyTorchProfiler(\n",
    "#     on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../logs/tb_logs/profiler0\"),\n",
    "#     schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "# )\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # profiler=profiler,\n",
    "    # logger=logger,\n",
    "    # accelerator=ACCELERATOR,\n",
    "    # devices=DEVICES,\n",
    "    min_epochs=1,\n",
    "    # max_steps=2,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    precision='bf16-mixed',\n",
    "    # precision=32,\n",
    "    fast_dev_run=True\n",
    "    # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.validate(model, data_module)\n",
    "# trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from model import NN\n",
    "from dataset import MnistDataModule\n",
    "import config\n",
    "#TODO: import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\") # to make lightning happy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"mnist_model_v1\")\n",
    "    profiler = PyTorchProfiler(\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"tb_logs/profiler0\"),\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "    )\n",
    "    model = NN(\n",
    "        input_size=config.INPUT_SIZE,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "    )\n",
    "    dm = MnistDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        profiler=profiler,\n",
    "        logger=logger,\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=1,\n",
    "        max_epochs=config.NUM_EPOCHS,\n",
    "        precision=config.PRECISION,\n",
    "        # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    )\n",
    "    trainer.fit(model, dm)\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>sparse_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>papular</td>\n",
       "      <td>0</td>\n",
       "      <td>919</td>\n",
       "      <td>1635</td>\n",
       "      <td>2918</td>\n",
       "      <td>00241a_A_P.jpg</td>\n",
       "      <td>1960</td>\n",
       "      <td>4032</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D:/Projects/Skin Disease Detection/Dataset/Lat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scabies</td>\n",
       "      <td>1006</td>\n",
       "      <td>1260</td>\n",
       "      <td>1713</td>\n",
       "      <td>2143</td>\n",
       "      <td>00240b_A_S.jpg</td>\n",
       "      <td>1960</td>\n",
       "      <td>4032</td>\n",
       "      <td>6.0</td>\n",
       "      <td>D:/Projects/Skin Disease Detection/Dataset/Lat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atopic</td>\n",
       "      <td>215</td>\n",
       "      <td>424</td>\n",
       "      <td>457</td>\n",
       "      <td>706</td>\n",
       "      <td>0052b_A_A.jpg</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>9.0</td>\n",
       "      <td>D:/Projects/Skin Disease Detection/Dataset/Lat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scabies</td>\n",
       "      <td>138</td>\n",
       "      <td>94</td>\n",
       "      <td>633</td>\n",
       "      <td>643</td>\n",
       "      <td>0044a_A_S.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "      <td>14.0</td>\n",
       "      <td>D:/Projects/Skin Disease Detection/Dataset/Lat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scabies</td>\n",
       "      <td>354</td>\n",
       "      <td>866</td>\n",
       "      <td>950</td>\n",
       "      <td>1217</td>\n",
       "      <td>0044a_A_S.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "      <td>14.0</td>\n",
       "      <td>D:/Projects/Skin Disease Detection/Dataset/Lat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_name  xmin  ymin  xmax  ymax      image_name  image_width  \\\n",
       "0    papular     0   919  1635  2918  00241a_A_P.jpg         1960   \n",
       "1    scabies  1006  1260  1713  2143  00240b_A_S.jpg         1960   \n",
       "2     atopic   215   424   457   706   0052b_A_A.jpg          720   \n",
       "3    scabies   138    94   633   643   0044a_A_S.jpg         1280   \n",
       "4    scabies   354   866   950  1217   0044a_A_S.jpg         1280   \n",
       "\n",
       "   image_height  patient_id  \\\n",
       "0          4032         3.0   \n",
       "1          4032         6.0   \n",
       "2          1280         9.0   \n",
       "3          1280        14.0   \n",
       "4          1280        14.0   \n",
       "\n",
       "                                            img_path  sparse_label  \n",
       "0  D:/Projects/Skin Disease Detection/Dataset/Lat...             1  \n",
       "1  D:/Projects/Skin Disease Detection/Dataset/Lat...             2  \n",
       "2  D:/Projects/Skin Disease Detection/Dataset/Lat...             0  \n",
       "3  D:/Projects/Skin Disease Detection/Dataset/Lat...             2  \n",
       "4  D:/Projects/Skin Disease Detection/Dataset/Lat...             2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths = glob(f'{DATA_DIR}/images/*')\n",
    "df = pd.read_csv(f'{DATA_DIR}/verified_annotation_from_xml.csv')\n",
    "\n",
    "df = pd.read_csv(f'{DATA_DIR}/verified_annotation_from_xml.csv')\n",
    "df['img_path'] =f'{DATA_DIR}/images/' + df['image_name']\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df['label_name'] = df['label_name'].apply(lambda x: x.lower())\n",
    "df['sparse_label'] = df['label_name'].map({'atopic': 0, 'papular': 1,'scabies': 2})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightningNetwork(\n",
    "    base_model = efficientnet_b0(),\n",
    "    dropout=0.3, \n",
    "    output_dims=[128, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from model import NN\n",
    "from dataset import MnistDataModule\n",
    "import config\n",
    "#TODO: import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\") # to make lightning happy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"mnist_model_v1\")\n",
    "    profiler = PyTorchProfiler(\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"tb_logs/profiler0\"),\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "    )\n",
    "    model = NN(\n",
    "        input_size=config.INPUT_SIZE,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "    )\n",
    "    dm = MnistDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        profiler=profiler,\n",
    "        logger=logger,\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=1,\n",
    "        max_epochs=config.NUM_EPOCHS,\n",
    "        precision=config.PRECISION,\n",
    "        # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    )\n",
    "    trainer.fit(model, dm)\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from model import NN\n",
    "from dataset import MnistDataModule\n",
    "import config\n",
    "#TODO: import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\") # to make lightning happy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=\"../logs/tb_logs\", \n",
    "        name=\"trail_v1\"\n",
    "    )\n",
    "    profiler = PyTorchProfiler(\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../logs/tb_logs/profiler0\"),\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "    )\n",
    "    base_model_name = 'efficientnet_b0'\n",
    "    model = LightningNetwork(\n",
    "            base_model=base_model_dict[base_model_name] ,\n",
    "            dropout=0.2, \n",
    "            output_dims=[128, 64]\n",
    ")\n",
    "    dm = MnistDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        profiler=profiler,\n",
    "        logger=logger,\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=1,\n",
    "        max_epochs=config.NUM_EPOCHS,\n",
    "        precision=config.PRECISION,\n",
    "        # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    )\n",
    "    trainer.fit(model, dm)\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"mnist_model_v1\")\n",
    "    profiler = PyTorchProfiler(\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"tb_logs/profiler0\"),\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "    )\n",
    "    base_model_name = 'efficientnet_b0'\n",
    "    model = LightningNetwork(\n",
    "            base_model=base_model_dict[base_model_name] ,\n",
    "            dropout=0.2, \n",
    "            output_dims=[128, 64]\n",
    ")\n",
    "    dm = MnistDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        profiler=profiler,\n",
    "        logger=logger,\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=1,\n",
    "        max_epochs=config.NUM_EPOCHS,\n",
    "        precision=config.PRECISION,\n",
    "        # callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    )\n",
    "    trainer.fit(model, dm)\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
